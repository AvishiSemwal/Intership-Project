{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# **Active Noise Cancellation - Selection Task #1**\n", "### **Human Activity Recognition using Deep Learning & Machine Learning**\n", "\n", "### **Author: Avishi Semwal**\n", "\n", "**Objective:**\n", "- Build models to classify human activities using the UCI HAR dataset.\n", "- Train Deep Learning models (LSTM, 1D CNN) on raw accelerometer data.\n", "- Extract features using TSFEL and train ML models (Random Forest, SVM, Logistic Regression).\n", "- Compare performances of different models.\n", "\n", "**Technologies Used:** Python, TensorFlow, TSFEL, Machine Learning, Deep Learning.\n", "\n", "**Dataset:** UCI HAR Dataset (Human Activity Recognition Using Smartphones)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# **Active Noise Cancellation - Selection Task #1**\n", "### **Human Activity Recognition using Deep Learning & Machine Learning**\n", "\n", "**Objective:**\n", "- Build models to classify human activities using the UCI HAR dataset.\n", "- Train Deep Learning models (LSTM, 1D CNN) on raw accelerometer data.\n", "- Extract features using TSFEL and train ML models (Random Forest, SVM, Logistic Regression).\n", "- Compare performances of different models."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import tensorflow as tf\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score\n", "import tsfel\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 1: Load and Explore the UCI HAR Dataset**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load UCI HAR Dataset\n", "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip'\n", "dataset_path = 'UCI_HAR_Dataset.zip'\n", "\n", "# Download dataset if not available\n", "import os\n", "import urllib.request\n", "import zipfile\n", "\n", "if not os.path.exists(dataset_path):\n", "    urllib.request.urlretrieve(dataset_url, dataset_path)\n", "\n", "# Extract dataset\n", "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n", "    zip_ref.extractall('UCI_HAR_Dataset')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define dataset paths\n", "train_x_path = 'UCI_HAR_Dataset/UCI HAR Dataset/train/X_train.txt'\n", "train_y_path = 'UCI_HAR_Dataset/UCI HAR Dataset/train/y_train.txt'\n", "test_x_path = 'UCI_HAR_Dataset/UCI HAR Dataset/test/X_test.txt'\n", "test_y_path = 'UCI_HAR_Dataset/UCI HAR Dataset/test/y_test.txt'\n", "\n", "# Load data into Pandas DataFrame\n", "X_train = pd.read_csv(train_x_path, delim_whitespace=True, header=None)\n", "y_train = pd.read_csv(train_y_path, delim_whitespace=True, header=None)\n", "X_test = pd.read_csv(test_x_path, delim_whitespace=True, header=None)\n", "y_test = pd.read_csv(test_y_path, delim_whitespace=True, header=None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 2: Preprocessing the Data**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Normalize the dataset\n", "scaler = StandardScaler()\n", "X_train_scaled = scaler.fit_transform(X_train)\n", "X_test_scaled = scaler.transform(X_test)\n", "\n", "# Reshape for deep learning models\n", "X_train_dl = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n", "X_test_dl = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 3: Train Deep Learning Models (LSTM, 1D CNN)**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define and train LSTM Model\n", "lstm_model = Sequential([\n", "    LSTM(50, activation='relu', input_shape=(X_train_dl.shape[1], 1)),\n", "    Dense(25, activation='relu'),\n", "    Dense(6, activation='softmax')\n", "])\n", "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n", "lstm_model.fit(X_train_dl, y_train, epochs=10, batch_size=32, validation_data=(X_test_dl, y_test))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 4: Feature Extraction using TSFEL**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Feature Engineering with TSFEL\n", "cfg = tsfel.get_features_by_domain()\n", "X_train_tsfel = tsfel.time_series_features_extractor(cfg, X_train, fs=50)\n", "X_test_tsfel = tsfel.time_series_features_extractor(cfg, X_test, fs=50)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 5: Train Machine Learning Models**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Random Forest, SVM, and Logistic Regression\n", "rf_model = RandomForestClassifier(n_estimators=100)\n", "rf_model.fit(X_train_tsfel, y_train.values.ravel())\n", "y_pred_rf = rf_model.predict(X_test_tsfel)\n", "\n", "svm_model = SVC()\n", "svm_model.fit(X_train_tsfel, y_train.values.ravel())\n", "y_pred_svm = svm_model.predict(X_test_tsfel)\n", "\n", "logistic_model = LogisticRegression(max_iter=1000)\n", "logistic_model.fit(X_train_tsfel, y_train.values.ravel())\n", "y_pred_logistic = logistic_model.predict(X_test_tsfel)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}